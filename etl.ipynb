{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# ETL Processes\n",
    "Use this notebook to develop the ETL process for each of your tables before completing the `etl.py` file to load the whole datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sql_queries import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"host=127.0.0.1 dbname=sparkifydb user=student password=student\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_files(filepath):\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        files = glob.glob(os.path.join(root,'*.json'))\n",
    "        for f in files :\n",
    "            all_files.append(os.path.abspath(f))\n",
    "    \n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Process `song_data`\n",
    "In this first part, you'll perform ETL on the first dataset, `song_data`, to create the `songs` and `artists` dimensional tables.\n",
    "\n",
    "Let's perform ETL on a single song file and load a single record into each table to start.\n",
    "- Use the `get_files` function provided above to get a list of all song JSON files in `data/song_data`\n",
    "- Select the first song in this list\n",
    "- Read the song file and view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Use the get_files function provided above to get a list of all song JSON files in data/song_data\n",
    "song_files = get_files('data/song_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace/data/song_data/A/A/A/TRAAAVG12903CFA543.json\n"
     ]
    }
   ],
   "source": [
    "#Select the first song in this list\n",
    "filepath =song_files[1]\n",
    "print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            artist_id  artist_latitude artist_location  artist_longitude  \\\n",
      "0  ARNTLGG11E2835DDB9              NaN                               NaN   \n",
      "\n",
      "  artist_name   duration  num_songs             song_id  \\\n",
      "0         Clp  266.39628          1  SOUDSGM12AC9618304   \n",
      "\n",
      "                               title  year  \n",
      "0  Insatiable (Instrumental Version)     0  \n"
     ]
    }
   ],
   "source": [
    "#Read the song file and view the data\n",
    "df = pd.read_json(filepath,lines=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## #1: `songs` Table\n",
    "#### Extract Data for Songs Table\n",
    "- Select columns for song ID, title, artist ID, year, and duration\n",
    "- Use `df.values` to select just the values from the dataframe\n",
    "- Index to select the first (only) record in the dataframe\n",
    "- Convert the array to a list and set it to `song_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SOUDSGM12AC9618304',\n",
       " 'Insatiable (Instrumental Version)',\n",
       " 'ARNTLGG11E2835DDB9',\n",
       " 0,\n",
       " 266.39628)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#song_id=df['song_id'].values[0]\n",
    "#title=df['title'].values[0]\n",
    "#artist_id=df['artist_id'].values[0]\n",
    "#year=int(df['year'].values[0])\n",
    "#duration=df['duration'].values[0]\n",
    "song_data = tuple(df[['song_id','title','artist_id','year','duration']].values[0])\n",
    "#song_data =[song_id,title,artist_id,year,duration]\n",
    "song_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Insert Record into Song Table\n",
    "Implement the `song_table_insert` query in `sql_queries.py` and run the cell below to insert a record for this song into the `songs` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `songs` table in the sparkify database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cur.execute(song_table_insert, song_data)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Run `test.ipynb` to see if you've successfully added a record to this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## #2: `artists` Table\n",
    "#### Extract Data for Artists Table\n",
    "- Select columns for artist ID, name, location, latitude, and longitude\n",
    "- Use `df.values` to select just the values from the dataframe\n",
    "- Index to select the first (only) record in the dataframe\n",
    "- Convert the array to a list and set it to `artist_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ARNTLGG11E2835DDB9', 'Clp', '', nan, nan)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#artist_data = [df['artist_id'].values[0],df['artist_name'].values[0],df['artist_location'].values[0],df['artist_latitude'].values[0],df['artist_longitude'].values[0]]\n",
    "artist_data =tuple(df[['artist_id','artist_name','artist_location','artist_latitude','artist_longitude']].values[0])\n",
    "artist_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Insert Record into Artist Table\n",
    "Implement the `artist_table_insert` query in `sql_queries.py` and run the cell below to insert a record for this song's artist into the `artists` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `artists` table in the sparkify database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cur.execute(artist_table_insert, artist_data)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Run `test.ipynb` to see if you've successfully added a record to this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Process `log_data`\n",
    "In this part, you'll perform ETL on the second dataset, `log_data`, to create the `time` and `users` dimensional tables, as well as the `songplays` fact table.\n",
    "\n",
    "Let's perform ETL on a single log file and load a single record into each table.\n",
    "- Use the `get_files` function provided above to get a list of all log JSON files in `data/log_data`\n",
    "- Select the first log file in this list\n",
    "- Read the log file and view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "log_files =  get_files('data/log_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "filepath = log_files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      artist       auth firstName gender  itemInSession  \\\n",
      "0                   Frumpies  Logged In  Anabelle      F              0   \n",
      "1  Kenny G with Peabo Bryson  Logged In  Anabelle      F              1   \n",
      "2                Biffy Clyro  Logged In  Anabelle      F              2   \n",
      "3                       None  Logged In      Lily      F              0   \n",
      "4                        HIM  Logged In      Lily      F              1   \n",
      "\n",
      "  lastName     length level                                     location  \\\n",
      "0  Simpson  134.47791  free  Philadelphia-Camden-Wilmington, PA-NJ-DE-MD   \n",
      "1  Simpson  264.75057  free  Philadelphia-Camden-Wilmington, PA-NJ-DE-MD   \n",
      "2  Simpson  189.83138  free  Philadelphia-Camden-Wilmington, PA-NJ-DE-MD   \n",
      "3    Burns        NaN  free        New York-Newark-Jersey City, NY-NJ-PA   \n",
      "4    Burns  212.06159  free        New York-Newark-Jersey City, NY-NJ-PA   \n",
      "\n",
      "  method      page  registration  sessionId                            song  \\\n",
      "0    PUT  NextSong  1.541044e+12        455                      Fuck Kitty   \n",
      "1    PUT  NextSong  1.541044e+12        455  By The Time This Night Is Over   \n",
      "2    PUT  NextSong  1.541044e+12        455                     God & Satan   \n",
      "3    GET      Home  1.540621e+12        456                            None   \n",
      "4    PUT  NextSong  1.540621e+12        456                       Beautiful   \n",
      "\n",
      "   status             ts                                          userAgent  \\\n",
      "0     200  1541903636796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...   \n",
      "1     200  1541903770796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...   \n",
      "2     200  1541904034796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...   \n",
      "3     200  1541910841796  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...   \n",
      "4     200  1541910973796  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...   \n",
      "\n",
      "  userId  \n",
      "0     69  \n",
      "1     69  \n",
      "2     69  \n",
      "3     32  \n",
      "4     32  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(filepath,lines=True)\n",
    "#print(log_files[1])\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## #3: `time` Table\n",
    "#### Extract Data for Time Table\n",
    "- Filter records by `NextSong` action\n",
    "- Convert the `ts` timestamp column to datetime\n",
    "  - Hint: the current timestamp is in milliseconds\n",
    "- Extract the timestamp, hour, day, week of year, month, year, and weekday from the `ts` column and set `time_data` to a list containing these values in order\n",
    "  - Hint: use pandas' [`dt` attribute](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.html) to access easily datetimelike properties.\n",
    "- Specify labels for these columns and set to `column_labels`\n",
    "- Create a dataframe, `time_df,` containing the time data for this file by combining `column_labels` and `time_data` into a dictionary and converting this into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(filepath,lines=True)\n",
    "\n",
    "#Filter records by NextSong action\n",
    "df=df[df['page']=='NextSong']\n",
    "\n",
    "#Convert the ts timestamp column to datetime\n",
    "#df['ts']=pd.to_datetime(df['ts'], unit='ms')\n",
    "\n",
    "#Extract the timestamp, hour, day, week of year, month, year, and weekday from the ts column and set time_data to a list containing these values in order\n",
    "#time_data=[df['ts'],df['ts'].dt.hour,df['ts'].dt.day,df['ts'].dt.week,df['ts'].dt.year,df['ts'].dt.weekday]\n",
    "#df.head()\n",
    "#Specify labels for these columns and set to column_labels\n",
    "#column_labels=['Timestamp','Hours','Day','Week','Year','Weekday']\n",
    "#Create a dataframe, time_df, containing the time data for this file by combining column_labels and time_data into a dictionary and converting this into a dataframe\n",
    "#time_df=pd.concat(time_data,axis=1)\n",
    "#time_df.columns=column_labels\n",
    "#print(time_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2018-11-11 02:33:56.796\n",
       "1   2018-11-11 02:36:10.796\n",
       "2   2018-11-11 02:40:34.796\n",
       "4   2018-11-11 04:36:13.796\n",
       "5   2018-11-11 04:36:46.796\n",
       "Name: ts, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.to_datetime(df['ts'], unit='ms')\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "time_data = [t.dt.time,t.dt.hour,t.dt.day,t.dt.week,t.dt.month,t.dt.year,t.dt.weekday]\n",
    "column_labels = ['Time','Hours','Day','Week','Month','Year','Weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Day</th>\n",
       "      <th>Week</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02:33:56.796000</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02:36:10.796000</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02:40:34.796000</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04:34:01.796000</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04:36:13.796000</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Time  Hours  Day  Week  Month  Year  Weekday\n",
       "0  02:33:56.796000      2   11    45     11  2018        6\n",
       "1  02:36:10.796000      2   11    45     11  2018        6\n",
       "2  02:40:34.796000      2   11    45     11  2018        6\n",
       "3  04:34:01.796000      4   11    45     11  2018        6\n",
       "4  04:36:13.796000      4   11    45     11  2018        6"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_df = pd.concat(time_data,axis=1)\n",
    "time_df.columns=column_labels\n",
    "time_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Insert Records into Time Table\n",
    "Implement the `time_table_insert` query in `sql_queries.py` and run the cell below to insert records for the timestamps in this log file into the `time` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `time` table in the sparkify database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i, row in time_df.iterrows():\n",
    "    cur.execute(time_table_insert, list(row))\n",
    "    #print(type(row))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Run `test.ipynb` to see if you've successfully added records to this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## #4: `users` Table\n",
    "#### Extract Data for Users Table\n",
    "- Select columns for user ID, first name, last name, gender and level and set to `user_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "usr_series=[df['userId'],df['firstName'],df['lastName'],df['gender'],df['level']]\n",
    "#user_df = df[['userId','firstName','lastName','gender','level']]\n",
    "#print(type(user_df))\n",
    "user_df = pd.concat(usr_series,axis=1)\n",
    "#print(type(user_df))\n",
    "#print(user_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Insert Records into Users Table\n",
    "Implement the `user_table_insert` query in `sql_queries.py` and run the cell below to insert records for the users in this log file into the `users` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `users` table in the sparkify database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty user_id.Record will be ignored..\n",
      "empty user_id.Record will be ignored..\n",
      "empty user_id.Record will be ignored..\n"
     ]
    }
   ],
   "source": [
    "for i, row in user_df.iterrows():\n",
    "    if not list(row)[0]==\"\":\n",
    "        cur.execute(user_table_insert, list(row))\n",
    "        conn.commit()\n",
    "    else:\n",
    "        print(\"empty user_id.Record will be ignored..\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Run `test.ipynb` to see if you've successfully added records to this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## #5: `songplays` Table\n",
    "#### Extract Data and Songplays Table\n",
    "This one is a little more complicated since information from the songs table, artists table, and original log file are all needed for the `songplays` table. Since the log file does not specify an ID for either the song or the artist, you'll need to get the song ID and artist ID by querying the songs and artists tables to find matches based on song title, artist name, and song duration time.\n",
    "- Implement the `song_select` query in `sql_queries.py` to find the song ID and artist ID based on the title, artist name, and duration of a song.\n",
    "- Select the timestamp, user ID, level, song ID, artist ID, session ID, location, and user agent and set to `songplay_data`\n",
    "\n",
    "#### Insert Records into Songplays Table\n",
    "- Implement the `songplay_table_insert` query and run the cell below to insert records for the songplay actions in this log file into the `songplays` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `songplays` table in the sparkify database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n",
      "No songid found for Fuck Kitty Frumpies 134.47791\n",
      "<class 'NoneType'>\n",
      "No songid found for By The Time This Night Is Over Kenny G with Peabo Bryson 264.75057\n",
      "<class 'NoneType'>\n",
      "No songid found for God & Satan Biffy Clyro 189.83138\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for Beautiful HIM 212.06159\n",
      "<class 'NoneType'>\n",
      "No songid found for Supreme Balloon Matmos 1449.11628\n",
      "<class 'NoneType'>\n",
      "No songid found for The One Gary Allan 259.83955\n",
      "<class 'NoneType'>\n",
      "No songid found for Five Roses Miracle Fortress 200.9073\n",
      "<class 'NoneType'>\n",
      "No songid found for Cuentale Don Omar 261.35465\n",
      "<class 'NoneType'>\n",
      "No songid found for D'Evils Jay-Z 212.27057\n",
      "<class 'NoneType'>\n",
      "No songid found for Easily (Album Version) Red Hot Chili Peppers 231.33995\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for Rebels of the Sacred Heart Flogging Molly 361.9522\n",
      "<class 'NoneType'>\n",
      "No songid found for Now_ Right Now Reverend Horton Heat 158.64118\n",
      "<class 'NoneType'>\n",
      "No songid found for I Made A Resolution Sea Wolf 232.61995\n",
      "<class 'NoneType'>\n",
      "No songid found for Lucky (Album Version) Jason Mraz & Colbie Caillat 189.6224\n",
      "<class 'NoneType'>\n",
      "No songid found for Enough\u0019s Enough Jamie Lidell 175.25506\n",
      "<class 'NoneType'>\n",
      "No songid found for Mushaboom (Postal Service Mix) Feist 212.79302\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for We're Going Out Tonight Sex Slaves 175.51628\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for To Them These Streets Belong Rise Against 169.482\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for Get Me Bodied BeyoncÃÂ© 359.54893\n",
      "<class 'NoneType'>\n",
      "No songid found for Never Leave Me Alone Nate Dogg 356.38812\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for Love Story Taylor Swift 233.89995\n",
      "<class 'NoneType'>\n",
      "No songid found for Sweet home Alabama Lynyrd Skynyrd 216.60689\n",
      "<class 'NoneType'>\n",
      "No songid found for Caught Out There (Explicit) Kelis 293.58975\n",
      "<class 'NoneType'>\n",
      "No songid found for Last Day Of Magic The Kills 203.38893\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for What A Feeling Collie Buddz featuring Paul Wall 271.62077\n",
      "<class 'NoneType'>\n",
      "No songid found for Fireflies Charttraxx Karaoke 225.17506\n",
      "<class 'NoneType'>\n",
      "No songid found for The Funeral (Album Version) Band Of Horses 321.14893\n",
      "<class 'NoneType'>\n",
      "No songid found for Clocks Coldplay 307.51302\n",
      "<class 'NoneType'>\n",
      "No songid found for Have A Nice Day Bon Jovi 228.75383\n",
      "<class 'NoneType'>\n",
      "No songid found for Alive (2006 Remastered Album Version) P.O.D. 203.7024\n",
      "<class 'NoneType'>\n",
      "No songid found for Plans (Replanned by Mogwai) Bloc Party 222.04036\n",
      "<class 'NoneType'>\n",
      "No songid found for Pa Pa Pa Los Prisioneros 211.12118\n",
      "<class 'NoneType'>\n",
      "No songid found for Lots More Stairs Octopus Project 175.25506\n",
      "<class 'NoneType'>\n",
      "No songid found for Ecoute Ce Scratch Roudoudou 18.41587\n",
      "<class 'NoneType'>\n",
      "No songid found for Tierra Tradicional Africando 253.54404\n",
      "<class 'NoneType'>\n",
      "No songid found for Simmons Incorporated RUN-DMC Featuring Method Man_ Kenny Cash_ Mike Ransom_ and Jamel Simmons 266.52689\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for I'm Goin' Away Graham Coxon 197.14567\n",
      "<class 'NoneType'>\n",
      "No songid found for In The Fade Queens Of The Stone Age 231.02649\n",
      "<class 'NoneType'>\n",
      "No songid found for Strawberry AndrÃÂ© (Album Version) Dance Gavin Dance 193.30567\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for Eyes As Candles Passion Pit 243.69587\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for Let's Get It Started Black Eyed Peas 229.61587\n",
      "<class 'NoneType'>\n",
      "No songid found for Ca plane pour moi Plastic Bertrand 180.00934\n",
      "<class 'NoneType'>\n",
      "No songid found for Strange Brew Cream 166.5824\n",
      "<class 'NoneType'>\n",
      "No songid found for A Message Coldplay 284.39465\n",
      "<class 'NoneType'>\n",
      "No songid found for Sweat the Battle Before the Battle Sweats You (Album Version) Cute Is What We Aim For 172.22485\n",
      "<class 'NoneType'>\n",
      "No songid found for Of Wolf And Man Metallica 256.9922\n",
      "<class 'NoneType'>\n",
      "No songid found for Tape Song The Kills 217.70404\n",
      "<class 'NoneType'>\n",
      "No songid found for The Pretender Foo Fighters 271.38567\n",
      "<class 'NoneType'>\n",
      "No songid found for Eyen [Chosen by fans on Warp20.net] Plaid 260.96281\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for It's New To Me The Van Pelt 208.71791\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for Make You Smile +44 224.57424\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for I May Never Find Chris Brown 275.1473\n",
      "<class 'NoneType'>\n",
      "No songid found for Black Horse And The Cherry Tree (Radio Version) KT Tunstall 170.47465\n",
      "<class 'NoneType'>\n",
      "No songid found for Kids In America Cascada 184.39791\n",
      "<class 'NoneType'>\n",
      "No songid found for Black Heart Inertia Incubus 293.38077\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for Black & Blue Miike Snow 220.83873\n",
      "<class 'NoneType'>\n",
      "No songid found for Sala De RecepÃÂ§ÃÂ£o Cartola 208.92689\n",
      "<class 'NoneType'>\n",
      "No songid found for Commander In Thief Kill The Client 70.68689\n",
      "<class 'NoneType'>\n",
      "No songid found for None None nan\n",
      "<class 'NoneType'>\n",
      "No songid found for Woman Wolfmother 175.82975\n",
      "<class 'NoneType'>\n",
      "No songid found for Wagon Wheel Old Crow Medicine Show 231.73179\n",
      "<class 'NoneType'>\n",
      "No songid found for Debbie Architecture In Helsinki 173.73995\n",
      "<class 'NoneType'>\n",
      "No songid found for I Think I'll Live Charlie Louvin 170.86649\n",
      "<class 'NoneType'>\n",
      "No songid found for La Derrota de Un Don Juan Miguel Morales 270.78485\n",
      "<class 'NoneType'>\n",
      "No songid found for Le Courage Des Oiseaux Dominique A 153.20771\n",
      "<class 'NoneType'>\n",
      "No songid found for Run With The Blind Cock Sparrer 203.25832\n",
      "<class 'NoneType'>\n",
      "No songid found for I Love You So Much It Hurts Jimmy Wakely 165.74649\n",
      "<class 'NoneType'>\n",
      "No songid found for A Little Death Around the Eyes Peter Doherty 217.02485\n",
      "<class 'NoneType'>\n",
      "No songid found for Thinking Of You Katy Perry 246.41261\n",
      "<class 'NoneType'>\n",
      "No songid found for You Love Me Anyway (Album) Sidewalk Prophets 260.62322\n",
      "<class 'NoneType'>\n",
      "No songid found for Torches Rise Against 221.17832\n",
      "<class 'NoneType'>\n",
      "No songid found for Wavin'  Flag K'Naan 220.49914\n",
      "<class 'NoneType'>\n",
      "No songid found for Holiday Patrick Jumpen 208.87465\n",
      "<class 'NoneType'>\n",
      "No songid found for Empire State Of Mind (Part II) Broken Down Alicia Keys 216.47628\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    #print(song_select)\n",
    "    # get songid and artistid from song and artist tables\n",
    "    cur.execute(song_select, (row.song, row.artist, row.length))\n",
    "    results = cur.fetchone()\n",
    "  \n",
    "    if results:\n",
    "        songid, artistid = results\n",
    "    else:\n",
    "        songid, artistid = None, None\n",
    "    #print(row)\n",
    "    # insert songplay record\n",
    "    #print(row.ts)\n",
    "    time=str(pd.to_datetime(row.ts, unit='ms').time())\n",
    "    #print(\"time \"+ str(time))\n",
    "    songplay_data = (time,row.userId,row.level,songid,artistid,row.sessionId,row.location,row.userAgent)\n",
    "    print(type(songid))    \n",
    "    if not songid==None:\n",
    "        print(songid+str(songid))\n",
    "        cur.execute(songplay_table_insert, songplay_data)\n",
    "        conn.commit()\n",
    "    else:\n",
    "        print(\"No songid found for \"+str(row.song) +\" \"+ str(row.artist)+\" \"+str(row.length))\n",
    "print(\"--------------------------\")\n",
    "#cur.execute('SELECT * FROM songplays')\n",
    "#res=cur.fetchall()\n",
    "#print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Run `test.ipynb` to see if you've successfully added records to this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Close Connection to Sparkify Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Implement `etl.py`\n",
    "Use what you've completed in this notebook to implement `etl.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
